---
title: 'Blog 1: Tidy Models'
author: David Simbandumwe
subtitle: Value of Opinionated Frameworks
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
  word_document:
    toc: yes
editor_options:
  chunk_output_type: inline
  markdown:
    wrap: sentence
bibliography: references.bib
---



```{r}

knitr::opts_chunk$set(echo = F, 
                      warning = F, 
                      message = F, 
                      eval = T , 
                      results="asis", 
                      fig.height=6, 
                      fig.width=8)

set.seed(1234)

```


# Introduction

The Tidymodels framework is a collection of modeling and machine learning packages using Tidyverse principles. In contrast to the flexibility of R, Tidymodels is an opinionated system with an underlying solution philosophy. For this blog post, I wanted to explore the implications of the Tidymodel approach on the development effort. Tidymodels goes beyond exposing modeling capabilities and dictates a solution methodology and workflow for problem-solving. 

Opinionated systems such as Tidymodels have several benefits, including:

- Consistency - Opinionated systems promote a consistent mental model, approach, and workflow for solving problems. 
- Encapsulation of Best Practices - Opinionated frameworks provide guardrails that inherently guide developers toward best practices. Furthermore, the execution model enforces a workflow and approach to problem-solving. 
- Faster Development - Reducing the required upfront decisions and providing framework support for everyday modeling tasks accelerates the development process. The individual developers and teams do not need to write the plumbing, connectivity, or boilerplate code for basic functions. 

In the negative column, the drawbacks of opinioned systems include:

- Required Buy-In - To use the Tidymodel framework, you must buy into the authors' decisions and problem framing. Utilizing individual elements of the framework without adopting the entire solution is a difficult prospect. 
- Hidden Decisions - Standardization of the interfaces to models simplifies the execution but involves some decisions regarding default values.




# Tidymodels

The Tidymodels framework is a collection of modeling and machine learning packages. The core packages that make up the Tidymodel universe include rsample, parsnip, recipes, workflows, tune, yardstick, broom, and dials. For this blog post, I will explore how these packages impact data preparation, model definition, and the model execution workflow. 




```{r}

library(tidyverse)
library(tidymodels)
library(workflowsets)
library(dotwhisker)
library(summarytools)
library(rstanarm)
library(ranger)
library(poissonreg)

```





## Tidy Data

The Tidyverse advocates for Tidy Data, a consistent representation of the model data. The data preparation step transforms data into a consistent model that adheres to the following rules:
a) Each variable must have its own column.
b) Each observation must have its own row.
c) Each value must have its own cell.

Uniform data that conforms to tidy data specifications is more consistent and easier to work with. Furthermore, the rules associated with Tidy Data enable efficient manipulation with tools in the Tidyverse such as dplyr, or ggplot2. 

<img src="tidy_data.png" width="1200" style="display: block; margin-left: auto; margin-right: auto; width: 75%;"/>




```{r}

rm(list=ls())

cfg <- list(
              fileName = './inst/data/Teams.csv',
              rSource = './hw1/Functions.R',
              viewMethod = 'view' # options(render, browser, view)
          )


```




```{r}

# styling
st_css()

 st_options(
   plain.ascii = FALSE,
   style = 'grid',
   dfSummary.style ='grid',
   freq.silent  = TRUE,
   headings     = FALSE,
   tmp.img.dir  = "./tmp",
   dfSummary.custom.1 =
     expression(
       paste(
         "Q1 - Q3 :",
         round(
           quantile(column_data, probs = .25, type = 2,
                    names = FALSE, na.rm = TRUE), digits = 1
         ), " - ",
         round(
           quantile(column_data, probs = .75, type = 2,
                    names = FALSE, na.rm = TRUE), digits = 1
         )
       )
     )
 )

#source('', local = knitr::knit_global())

```



```{r}

# read data
df <- read.csv('./inst/data/Teams.csv')
df <- sample_n(df, size=500)
statistics <- c('R', 'H', 'X2B', 'X3B', 'HR', 
                    'RA', 'ER', 'HA', 'HRA')


# Preprocess Data
df <- df %>% select('yearID', 'lgID', 'teamID', 'franchID', 'name', 'divID', 'G', 'W', 'L', 
                    'R', 'H', 'X2B', 'X3B', 'HR', 
                    'RA', 'ER', 'HA', 'HRA')

df$wPer <- round(df$W / df$G, 3)
df$pythPer <- (df$R^2) / ((df$R^2) + (df$RA^2))


df <- df %>% mutate(era_cat = case_when(yearID >= 1969 ~ '1969+',
                                                yearID >= 1900 & yearID < 1969 ~ '1900-1969',
                                                yearID < 1900 ~ '1900-'))

df$era_cat <- factor(df$era_cat)



# Split Data
data_split <- initial_split(df, prop = 0.8, strata = era_cat)
train_data <- training(data_split)
test_data  <- testing(data_split)


```



```{r}
train_data %>% 
  skimr::skim()

```



```{r}

print(
  dfSummary(train_data %>% select(-c('teamID','franchID','name')), 
            varnumbers   = TRUE,
            na.col       = TRUE,
            graph.magnif = .8,
            tmp.img.dir  = "/tmp"),
  method = cfg$viewMethod
)


```



```{r}


ggplot(sample_n(train_data, size=100, weight_by = era_cat),
       aes(x = wPer, 
           y = pythPer, 
           group = era_cat, 
           col = era_cat)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) +
  scale_color_viridis_d(option = "plasma", end = .7)

```




# Approach to Building Models and Execution

In non-opinionated systems, there are several approaches to accomplishing a specific task empowering the user to make their own decisions. This flexibility is diminished in opinionated systems. Opinionated systems have a predefined approach or set of approaches for accomplishing tasks.

The Tidymodel model definition and model execution workflow are detailed below. 



## Recipe

The Tidymodels recipe is similar to the formula definition in the lm() function; however, it allows for feature engineering, variable role definition, and inheritance. The recipe definition provides a programmatically compact methodology for describing a collection of recipes in a single location. 

```{r}


base_recipe <- 
   recipe(W ~ pythPer + era_cat + yearID + teamID + franchID + 
            R + H + X2B + X3B + HR + RA + ER + HA + HRA, data = train_data) %>% 
   update_role(yearID, teamID, franchID, new_role = "ID") %>%
   step_dummy(all_nominal_predictors()) %>% 
   step_zv(all_predictors()) %>% 
   step_normalize(all_predictors())


filter_rec <- 
   base_recipe %>% 
   step_corr(all_of(statistics), threshold = tune())


pca_rec <- 
   base_recipe %>% 
   step_pca(all_of(statistics), num_comp = tune()) %>% 
   step_normalize(all_predictors())

```




# Model Specification

A unified interface to the available model is provided by the parsnip package. This interface decouples the model definition from the semantic details of the underlying package. Users can rapidly experiment with a range of models without getting bogged down in the semantic details of the underlying packages. The level of abstraction from the underlying model reduces the learning curve required to execute different models.


```{r}

lm_model <- 
  linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")

lms_model <- 
  linear_reg() %>% 
  set_engine("stan") %>% 
  set_mode("regression")

rf_model <- rand_forest(mtry = 10, trees = 2000) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")


```




# Workflow

The recipe, model specification, pre-processing, and post-processing definitions can be bundled together in a workflow. The workflow package offers coordination and synchronization. 


```{r}

team_wfl_set <- 
   workflow_set(
      preproc = list(simple = base_recipe, 
                     filter = filter_rec, 
                     pca = pca_rec),
      models = list(lm = lm_model, 
                    stan = lms_model,
                    rf = rf_model),
      cross = TRUE
   )
team_wfl_set

```





# Model Selection


```{r}


splits <- 
   vfold_cv(
      train_data,
      v = 10,
      strata = era_cat
   )
splits

```




```{r}

team_wfl_set <- 
   team_wfl_set %>% 
   workflow_map("tune_grid", resamples = splits, grid = 10, 
                metrics = metric_set(mae), verbose = TRUE)

team_wfl_set

```




```{r}

autoplot(team_wfl_set)
autoplot(team_wfl_set, select_best = TRUE)

```



```{r}


rank_results(team_wfl_set, rank_metric = "mae", select_best = TRUE) %>% 
   select(rank, mean, model, wflow_id, .config)


```



# Model Selection

```{r}

autoplot(team_wfl_set, metric = "mae", id = "filter_rf")


```




# Prediction


```{r}


tmp_wfl <- extract_workflow(team_wfl_set,id = 'simple_rf')



tmp_wfl.fit <- 
  tmp_wfl %>% 
  #finalize_workflow() %>% 
  fit(data = train_data)



tmp_rec <- 
   team_wfl_set %>% 
   extract_workflow_set_result("simple_rf")
tmp_rec



wins_fit <- 
  tmp_wfl %>% 
  fit(data = train_data)


# Make predictions on test set
pred <- tmp_wfl.fit  %>% predict(new_data = test_data)



results <- test_data %>% 
  bind_cols(tmp_wfl.fit %>% 
    predict(new_data = test_data) %>% 
      rename(predictions = .pred))



```



```{r}

n <- nrow(test_data)
x <- test_data$W
e <- pred$.pred - test_data$W


plot(x, e,  
     xlab = "wins", 
     ylab = "residuals", 
     bg = "steelblue", 
     col = "darkgray", cex = 1.5, pch = 21, frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : n) 
  lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 1)

```


simple_rf

```{r}


tmp_results <- 
   team_wfl_set %>% 
   extract_workflow_set_result("simple_rf") %>% 
   select_best(metric = "mae")
tmp_results

tmp_test_results <- 
   team_wfl_set %>% 
   extract_workflow("simple_rf") %>% 
   finalize_workflow(tmp_results) %>% 
   last_fit(split = data_split)

collect_metrics(tmp_test_results)


m0 <- collect_metrics(team_wfl_set)




```



```{r}

m0 %>% 
ggplot(aes(x=.metric, y=mean, fill=wflow_id)) + 
	geom_bar(stat = 'identity', width=0.3, position=position_dodge()) +
	facet_wrap(vars(.config),scales = "free", ncol = 5) +
	coord_flip() +
	ggtitle("Model Performance (MASE)")


```


# Conclusion

With opinionated systems, the design decisions are made upfront when you select the framework, and the user has less flexibility on the backend. With non-opinionated systems, the user maintains optionality and flexibility throughout the process.

If flexibility or visibility into the modeling process is important, then using the individual models directly might be more effective. Furthermore, the abstraction in the Tidymodels framework may not be a good option for educational purposes or the execution of a single use case. If you need to use specific parameters for the model execution, then the parsnip abstraction might be an impediment. 

However, when we start to view broader problems that require the exploration of different models or model specifications, then the benefits of the Tidymodel framework may make it a good option. 






